
				 Aum Sri Sai Ram
FER on AffectNet using GACNN


Total included  287651 {0: 74874, 1: 134415, 2: 25459, 3: 14090, 4: 6378, 5: 3803, 6: 24882, 7: 3750}
Total included  4000 {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500}
length of  train Database for training: 287651
length of  test Database: 4000
Training starting:

Training Epoch: [0][0/2248]	Time  (12.921242475509644)	Data (3.7475874423980713)	loss  (2.0778088569641113)	Prec1  (10.15625) 	
Training Epoch: [0][100/2248]	Time  (2.3537150208312685)	Data (0.04042816398167374)	loss  (1.9269937607321408)	Prec1  (25.734838485717773) 	
Training Epoch: [0][200/2248]	Time  (2.303085724512736)	Data (0.021482531704119782)	loss  (1.7129281350036165)	Prec1  (34.69371795654297) 	
Training Epoch: [0][300/2248]	Time  (2.2906687243832304)	Data (0.014828263723176974)	loss  (1.5901592356025975)	Prec1  (39.51671600341797) 	
Training Epoch: [0][400/2248]	Time  (2.2871907072471562)	Data (0.011668274824756042)	loss  (1.5034216899526982)	Prec1  (43.00187301635742) 	
Training Epoch: [0][500/2248]	Time  (2.2783984942826443)	Data (0.009862308254736864)	loss  (1.4430500418840053)	Prec1  (45.46999740600586) 	
Training Epoch: [0][600/2248]	Time  (2.276802366466173)	Data (0.00861886495758412)	loss  (1.3936501906041099)	Prec1  (47.407962799072266) 	
Training Epoch: [0][700/2248]	Time  (2.2765584066829057)	Data (0.007708425698708876)	loss  (1.3527556514944057)	Prec1  (49.100616455078125) 	
Training Epoch: [0][800/2248]	Time  (2.2763971175147355)	Data (0.007069371612777424)	loss  (1.318152549189426)	Prec1  (50.50132369995117) 	
Training Epoch: [0][900/2248]	Time  (2.2796702808333555)	Data (0.006491118874586912)	loss  (1.289558545003059)	Prec1  (51.66135025024414) 	
Training Epoch: [0][1000/2248]	Time  (2.279352290527923)	Data (0.006108099883133834)	loss  (1.2628622542132626)	Prec1  (52.699642181396484) 	
Training Epoch: [0][1100/2248]	Time  (2.280416686788242)	Data (0.005780612415448846)	loss  (1.2378400383918098)	Prec1  (53.71608352661133) 	
Training Epoch: [0][1200/2248]	Time  (2.2798641363250325)	Data (0.005520419018353947)	loss  (1.2150431330456126)	Prec1  (54.640663146972656) 	
Training Epoch: [0][1300/2248]	Time  (2.27959149805607)	Data (0.005253399270575932)	loss  (1.1924757942339717)	Prec1  (55.552818298339844) 	
Training Epoch: [0][1400/2248]	Time  (2.2793239367850586)	Data (0.005078337347396862)	loss  (1.1711784976027337)	Prec1  (56.4423828125) 	
Training Epoch: [0][1500/2248]	Time  (2.280334096841221)	Data (0.00490735007634884)	loss  (1.1513038519062573)	Prec1  (57.22227096557617) 	
Training Epoch: [0][1600/2248]	Time  (2.279516676528092)	Data (0.004686253432703346)	loss  (1.1325587377110398)	Prec1  (57.96718978881836) 	
Training Epoch: [0][1700/2248]	Time  (2.2782355495791515)	Data (0.004528923500011698)	loss  (1.115170593860218)	Prec1  (58.67182540893555) 	
Training Epoch: [0][1800/2248]	Time  (2.2781415006837733)	Data (0.0044017341122370435)	loss  (1.0979717302362102)	Prec1  (59.36111831665039) 	
Training Epoch: [0][1900/2248]	Time  (2.278041261801401)	Data (0.004295911367537786)	loss  (1.0823130966298897)	Prec1  (59.983642578125) 	
Training Epoch: [0][2000/2248]	Time  (2.277750846804648)	Data (0.004198336827641782)	loss  (1.0660843814926586)	Prec1  (60.645851135253906) 	
Training Epoch: [0][2100/2248]	Time  (2.277799932460794)	Data (0.004106306564461782)	loss  (1.0503477482413293)	Prec1  (61.28852462768555) 	
Training Epoch: [0][2200/2248]	Time  (2.2775251986708547)	Data (0.004013267445163476)	loss  (1.035721739751542)	Prec1  (61.87102508544922) 	
Testing Epoch: [0][0/32]	Time  (3.7805275917053223)	Data (2.738273859024048)	loss  (1.182660460472107)	Prec1  (60.9375) 	
Testing Epoch: [0][31/32]	Time  (0.6600164249539375)	Data (0.08565489947795868)	loss  (1.4194503917694092)	Prec1  (55.05000305175781) 	
Epoch: 0   Test Acc: 55.05000305175781

******************************
	Adjusted learning rate: 1

0.00095
Training Epoch: [1][0/2248]	Time  (6.52182936668396)	Data (4.087254047393799)	loss  (0.7160829901695251)	Prec1  (76.5625) 	
Training Epoch: [1][100/2248]	Time  (2.3192314511478536)	Data (0.04255824041838693)	loss  (0.6925848622133236)	Prec1  (75.5956039428711) 	
Training Epoch: [1][200/2248]	Time  (2.299581065106748)	Data (0.0222495646026004)	loss  (0.6821769600483909)	Prec1  (75.94837951660156) 	
Training Epoch: [1][300/2248]	Time  (2.2952643169517137)	Data (0.015423872938187812)	loss  (0.6746815246997085)	Prec1  (76.05117797851562) 	
Training Epoch: [1][400/2248]	Time  (2.290175445656527)	Data (0.012208706720214235)	loss  (0.6641432499499095)	Prec1  (76.39884948730469) 	
Training Epoch: [1][500/2248]	Time  (2.287562764333394)	Data (0.010282996171962716)	loss  (0.6565288042355916)	Prec1  (76.67009735107422) 	
Training Epoch: [1][600/2248]	Time  (2.286200727678575)	Data (0.008821235123569278)	loss  (0.6505742817373323)	Prec1  (76.83028411865234) 	
Training Epoch: [1][700/2248]	Time  (2.285238451012191)	Data (0.007918726190520762)	loss  (0.6427541041850363)	Prec1  (77.12085723876953) 	
Training Epoch: [1][800/2248]	Time  (2.283534176787187)	Data (0.007235395476761531)	loss  (0.634989720419254)	Prec1  (77.41202545166016) 	
Training Epoch: [1][900/2248]	Time  (2.2834707063257893)	Data (0.006720423036886505)	loss  (0.6275307295655834)	Prec1  (77.72960662841797) 	
Training Epoch: [1][1000/2248]	Time  (2.2830425454424574)	Data (0.006177961052238167)	loss  (0.6215829318100875)	Prec1  (77.94393157958984) 	
Training Epoch: [1][1100/2248]	Time  (2.2822215416342644)	Data (0.005702509000883873)	loss  (0.6151844022979962)	Prec1  (78.1789321899414) 	
Training Epoch: [1][1200/2248]	Time  (2.2815576113828713)	Data (0.005401931337075468)	loss  (0.6078696113194554)	Prec1  (78.48797607421875) 	
Training Epoch: [1][1300/2248]	Time  (2.2817425132255935)	Data (0.005189340541584504)	loss  (0.6010664550732137)	Prec1  (78.7411117553711) 	
Training Epoch: [1][1400/2248]	Time  (2.2810222280612593)	Data (0.0049944029460201765)	loss  (0.5944668047348147)	Prec1  (78.99212646484375) 	
Training Epoch: [1][1500/2248]	Time  (2.2813537921371814)	Data (0.004822302627055189)	loss  (0.5879367142419352)	Prec1  (79.225830078125) 	
Training Epoch: [1][1600/2248]	Time  (2.281865092235234)	Data (0.004676043726666729)	loss  (0.5825122693119609)	Prec1  (79.44205474853516) 	
Training Epoch: [1][1700/2248]	Time  (2.281487166355947)	Data (0.004505283337771927)	loss  (0.5770647075686435)	Prec1  (79.63927459716797) 	
Training Epoch: [1][1800/2248]	Time  (2.2807069961922757)	Data (0.004365803863127188)	loss  (0.5716254731835689)	Prec1  (79.85580444335938) 	
Training Epoch: [1][1900/2248]	Time  (2.28018454211063)	Data (0.004275170330747939)	loss  (0.5673633193511953)	Prec1  (80.02901458740234) 	
Training Epoch: [1][2000/2248]	Time  (2.280057368905231)	Data (0.0041184324076746414)	loss  (0.5624005663311523)	Prec1  (80.19623565673828) 	
Training Epoch: [1][2100/2248]	Time  (2.279850314538403)	Data (0.004032604924728052)	loss  (0.5577060986223361)	Prec1  (80.37393188476562) 	
Training Epoch: [1][2200/2248]	Time  (2.2794208215724767)	Data (0.003944195492166868)	loss  (0.5526380086286347)	Prec1  (80.56742858886719) 	
Testing Epoch: [1][0/32]	Time  (3.9055750370025635)	Data (2.817606210708618)	loss  (1.4195696115493774)	Prec1  (66.40625) 	
Testing Epoch: [1][31/32]	Time  (0.7080943211913109)	Data (0.0881195217370987)	loss  (1.8011570854187011)	Prec1  (52.72500228881836) 	
Epoch: 1   Test Acc: 52.72500228881836

******************************
	Adjusted learning rate: 2

0.0009025
Training Epoch: [2][0/2248]	Time  (6.01918625831604)	Data (3.537637948989868)	loss  (0.35378918051719666)	Prec1  (85.9375) 	
Training Epoch: [2][100/2248]	Time  (2.312512012991575)	Data (0.03761429361777731)	loss  (0.4321608555198896)	Prec1  (85.1098403930664) 	
Training Epoch: [2][200/2248]	Time  (2.2934582185982473)	Data (0.020262269831415432)	loss  (0.4297959405687911)	Prec1  (85.25730895996094) 	
Training Epoch: [2][300/2248]	Time  (2.2904937473246427)	Data (0.014147192140750315)	loss  (0.43165858550325187)	Prec1  (85.22632598876953) 	
Training Epoch: [2][400/2248]	Time  (2.2889693823835797)	Data (0.011241320065429383)	loss  (0.4295529813094627)	Prec1  (85.33744049072266) 	
Training Epoch: [2][500/2248]	Time  (2.2892932787150917)	Data (0.009541588153191907)	loss  (0.4272274218514532)	Prec1  (85.39639282226562) 	
Training Epoch: [2][600/2248]	Time  (2.287055091730965)	Data (0.00834735102344075)	loss  (0.4263277382600724)	Prec1  (85.44352722167969) 	
Training Epoch: [2][700/2248]	Time  (2.2857973585795404)	Data (0.0075210579451752795)	loss  (0.42328058038645566)	Prec1  (85.58309936523438) 	
Training Epoch: [2][800/2248]	Time  (2.2847336163086243)	Data (0.006889019119605589)	loss  (0.4196640332316638)	Prec1  (85.73365020751953) 	
Training Epoch: [2][900/2248]	Time  (2.2846117771161385)	Data (0.006432748661189445)	loss  (0.416551755763979)	Prec1  (85.86553192138672) 	
Training Epoch: [2][1000/2248]	Time  (2.28360074669212)	Data (0.00599233587305029)	loss  (0.41413570648723547)	Prec1  (85.9616928100586) 	
Training Epoch: [2][1100/2248]	Time  (2.2826374921876664)	Data (0.005602921711976262)	loss  (0.4109660019044114)	Prec1  (86.06096649169922) 	
Training Epoch: [2][1200/2248]	Time  (2.2827783061701687)	Data (0.00532303404351456)	loss  (0.40769791395886557)	Prec1  (86.17102813720703) 	
Training Epoch: [2][1300/2248]	Time  (2.2830573374449887)	Data (0.005039281244006732)	loss  (0.40500534778828806)	Prec1  (86.24615478515625) 	
Training Epoch: [2][1400/2248]	Time  (2.2827778480292897)	Data (0.004842806338923561)	loss  (0.4025830805493116)	Prec1  (86.31278991699219) 	
Training Epoch: [2][1500/2248]	Time  (2.2825909040515855)	Data (0.004688133961514264)	loss  (0.4001296035533425)	Prec1  (86.406982421875) 	
Training Epoch: [2][1600/2248]	Time  (2.2823564464192625)	Data (0.004541921734735417)	loss  (0.39806758257316693)	Prec1  (86.4937973022461) 	
Training Epoch: [2][1700/2248]	Time  (2.2818001226282765)	Data (0.0043893840157375975)	loss  (0.3955103114799217)	Prec1  (86.59197998046875) 	
Training Epoch: [2][1800/2248]	Time  (2.2820230034706923)	Data (0.004233501938433862)	loss  (0.3930171898823192)	Prec1  (86.6718978881836) 	
Training Epoch: [2][1900/2248]	Time  (2.2815159980025435)	Data (0.004124465583187226)	loss  (0.39088561587713694)	Prec1  (86.76395416259766) 	
Training Epoch: [2][2000/2248]	Time  (2.2820545852571534)	Data (0.004051350284254235)	loss  (0.3884981198497917)	Prec1  (86.86048126220703) 	
Training Epoch: [2][2100/2248]	Time  (2.2820597619797036)	Data (0.003990742094683568)	loss  (0.38678044869410655)	Prec1  (86.93293762207031) 	
Training Epoch: [2][2200/2248]	Time  (2.282178764828548)	Data (0.00391792481945407)	loss  (0.38451560543023255)	Prec1  (87.01761627197266) 	
Testing Epoch: [2][0/32]	Time  (3.7465624809265137)	Data (2.8988847732543945)	loss  (1.6755852699279785)	Prec1  (58.59375) 	
Testing Epoch: [2][31/32]	Time  (0.660085491836071)	Data (0.09066604822874069)	loss  (2.1407162704467773)	Prec1  (52.82500076293945) 	
Epoch: 2   Test Acc: 52.82500076293945

******************************
	Adjusted learning rate: 3

0.000857375
Training Epoch: [3][0/2248]	Time  (6.660971641540527)	Data (3.965423107147217)	loss  (0.4020998775959015)	Prec1  (87.5) 	
Training Epoch: [3][100/2248]	Time  (2.3384015088034147)	Data (0.04185628654933212)	loss  (0.3323615491390228)	Prec1  (88.98514556884766) 	
Training Epoch: [3][200/2248]	Time  (2.3123090492552194)	Data (0.022420358895069332)	loss  (0.33132096798858834)	Prec1  (89.02751922607422) 	
Training Epoch: [3][300/2248]	Time  (2.302534031313519)	Data (0.015556839217379244)	loss  (0.3281644289675741)	Prec1  (89.09623718261719) 	
Training Epoch: [3][400/2248]	Time  (2.2971033740816567)	Data (0.012412573631267595)	loss  (0.32195321914561076)	Prec1  (89.23200225830078) 	
Training Epoch: [3][500/2248]	Time  (2.297123131399859)	Data (0.010468364951615324)	loss  (0.32035197710205693)	Prec1  (89.35877990722656) 	
Training Epoch: [3][600/2248]	Time  (2.2924903653029)	Data (0.009145933459086743)	loss  (0.31768450659146524)	Prec1  (89.47067260742188) 	
Training Epoch: [3][700/2248]	Time  (2.2889152821392544)	Data (0.008229423691644817)	loss  (0.31435034852395216)	Prec1  (89.59522247314453) 	
Training Epoch: [3][800/2248]	Time  (2.287170267283693)	Data (0.007490020268567641)	loss  (0.3110147430730074)	Prec1  (89.71305084228516) 	
Training Epoch: [3][900/2248]	Time  (2.286105001673979)	Data (0.006900953796674621)	loss  (0.3097796570282268)	Prec1  (89.74317169189453) 	
Training Epoch: [3][1000/2248]	Time  (2.2846961135749932)	Data (0.0064696674937611215)	loss  (0.3091974935897223)	Prec1  (89.75009155273438) 	
Training Epoch: [3][1100/2248]	Time  (2.2841818830730913)	Data (0.006000446905123981)	loss  (0.30764665073638175)	Prec1  (89.84729766845703) 	
Training Epoch: [3][1200/2248]	Time  (2.2844517796760195)	Data (0.00570557615739122)	loss  (0.306523159109087)	Prec1  (89.90229797363281) 	
Training Epoch: [3][1300/2248]	Time  (2.283424320631445)	Data (0.005458138705582732)	loss  (0.30603452297149486)	Prec1  (89.9404296875) 	
Training Epoch: [3][1400/2248]	Time  (2.2828470753568313)	Data (0.005273974341719939)	loss  (0.3050346508101001)	Prec1  (89.96085357666016) 	
Training Epoch: [3][1500/2248]	Time  (2.282169489762054)	Data (0.005108921469091813)	loss  (0.30281175788166836)	Prec1  (90.02592468261719) 	
Training Epoch: [3][1600/2248]	Time  (2.2818893719136453)	Data (0.004889709959917706)	loss  (0.30129615920622)	Prec1  (90.07456970214844) 	
Training Epoch: [3][1700/2248]	Time  (2.281603609653587)	Data (0.0047427018483479815)	loss  (0.30030851742402725)	Prec1  (90.10600280761719) 	
Training Epoch: [3][1800/2248]	Time  (2.2814127676093796)	Data (0.004630314780896667)	loss  (0.2982721148448676)	Prec1  (90.18470001220703) 	
Training Epoch: [3][1900/2248]	Time  (2.281014855694357)	Data (0.00453695092058257)	loss  (0.29668940114213066)	Prec1  (90.25143432617188) 	
Training Epoch: [3][2000/2248]	Time  (2.2791623139846093)	Data (0.004422629374018435)	loss  (0.2951949981563929)	Prec1  (90.31500244140625) 	
Training Epoch: [3][2100/2248]	Time  (2.2774440574963735)	Data (0.004334919456071595)	loss  (0.2937955305490932)	Prec1  (90.36248016357422) 	
Training Epoch: [3][2200/2248]	Time  (2.275672970983669)	Data (0.004224557759598243)	loss  (0.29213385645135975)	Prec1  (90.41983795166016) 	
Testing Epoch: [3][0/32]	Time  (3.69535493850708)	Data (2.827988386154175)	loss  (1.5989990234375)	Prec1  (62.5) 	
Testing Epoch: [3][31/32]	Time  (0.7031625658273697)	Data (0.08844269812107086)	loss  (2.1185540943145753)	Prec1  (52.900001525878906) 	
Epoch: 3   Test Acc: 52.900001525878906

******************************
	Adjusted learning rate: 4

0.0008145062499999999
Training Epoch: [4][0/2248]	Time  (5.750796318054199)	Data (3.421640157699585)	loss  (0.3639001250267029)	Prec1  (86.71875) 	
Training Epoch: [4][100/2248]	Time  (2.275083952611036)	Data (0.036424849293019514)	loss  (0.24414376995646128)	Prec1  (92.11788177490234) 	
Training Epoch: [4][200/2248]	Time  (2.256531781818143)	Data (0.01896839711203504)	loss  (0.25041053110539024)	Prec1  (91.89598846435547) 	
Training Epoch: [4][300/2248]	Time  (2.252034136623243)	Data (0.01352471845886636)	loss  (0.25004397389599653)	Prec1  (91.96947479248047) 	
Training Epoch: [4][400/2248]	Time  (2.248635147575131)	Data (0.01060211331469757)	loss  (0.2474693638688311)	Prec1  (92.06281280517578) 	
Training Epoch: [4][500/2248]	Time  (2.2474239200888992)	Data (0.008838363750252182)	loss  (0.24756630847672978)	Prec1  (92.07054901123047) 	
Training Epoch: [4][600/2248]	Time  (2.246051483265374)	Data (0.007722622542928737)	loss  (0.24680568732804745)	Prec1  (92.09390258789062) 	
Training Epoch: [4][700/2248]	Time  (2.245810181200079)	Data (0.006976142929556026)	loss  (0.24465128169335243)	Prec1  (92.17747497558594) 	
Training Epoch: [4][800/2248]	Time  (2.246354662077257)	Data (0.00639175803176175)	loss  (0.24348517851473836)	Prec1  (92.22554016113281) 	
Training Epoch: [4][900/2248]	Time  (2.2461415033097007)	Data (0.005837074792080794)	loss  (0.24331629300256416)	Prec1  (92.23432922363281) 	
Training Epoch: [4][1000/2248]	Time  (2.2458724313444427)	Data (0.005402669325456038)	loss  (0.24257114380002617)	Prec1  (92.25540161132812) 	
Training Epoch: [4][1100/2248]	Time  (2.245835157874278)	Data (0.0050319051006292885)	loss  (0.240628724445764)	Prec1  (92.31380462646484) 	
Training Epoch: [4][1200/2248]	Time  (2.245519841739677)	Data (0.004829872657019927)	loss  (0.23960157027848059)	Prec1  (92.32865905761719) 	
Training Epoch: [4][1300/2248]	Time  (2.245526791535186)	Data (0.00463935432756616)	loss  (0.238561604529917)	Prec1  (92.35504150390625) 	
Training Epoch: [4][1400/2248]	Time  (2.2457463256296815)	Data (0.004484271424570567)	loss  (0.23809751801240622)	Prec1  (92.37654113769531) 	
Training Epoch: [4][1500/2248]	Time  (2.2454081385394558)	Data (0.004358048759882328)	loss  (0.23736880755400674)	Prec1  (92.41183471679688) 	
Training Epoch: [4][1600/2248]	Time  (2.245433059355231)	Data (0.0042327585107158824)	loss  (0.23666676456372787)	Prec1  (92.44320678710938) 	
Training Epoch: [4][1700/2248]	Time  (2.2454285733774086)	Data (0.004129392129403574)	loss  (0.23615083129948408)	Prec1  (92.4713363647461) 	
Training Epoch: [4][1800/2248]	Time  (2.2456748621917844)	Data (0.004009760730071971)	loss  (0.23501651234374585)	Prec1  (92.48897552490234) 	
Training Epoch: [4][1900/2248]	Time  (2.2458468695053107)	Data (0.003863793934476432)	loss  (0.23336844715333374)	Prec1  (92.53887939453125) 	
Training Epoch: [4][2000/2248]	Time  (2.2467254435402464)	Data (0.003848170471572685)	loss  (0.23162798899998968)	Prec1  (92.5892562866211) 	
Training Epoch: [4][2100/2248]	Time  (2.2474625881146046)	Data (0.0038206765675533392)	loss  (0.2304460067995272)	Prec1  (92.6370620727539) 	
Training Epoch: [4][2200/2248]	Time  (2.2474373132193537)	Data (0.0037758943981498223)	loss  (0.229546300325541)	Prec1  (92.66739654541016) 	
Testing Epoch: [4][0/32]	Time  (3.6096789836883545)	Data (2.777815341949463)	loss  (2.0926613807678223)	Prec1  (54.6875) 	
Testing Epoch: [4][31/32]	Time  (0.6640486642718315)	Data (0.08687761425971985)	loss  (2.678680431365967)	Prec1  (50.500003814697266) 	
Epoch: 4   Test Acc: 50.500003814697266

******************************
	Adjusted learning rate: 5

0.0007737809374999998
Training Epoch: [5][0/2248]	Time  (6.419138431549072)	Data (4.00507664680481)	loss  (0.147158682346344)	Prec1  (95.3125) 	
Training Epoch: [5][100/2248]	Time  (2.2866292637173493)	Data (0.04246924655272229)	loss  (0.20639741656803848)	Prec1  (93.57982635498047) 	
Training Epoch: [5][200/2248]	Time  (2.265954085250399)	Data (0.022105900209341476)	loss  (0.20848163335922346)	Prec1  (93.52845001220703) 	
Training Epoch: [5][300/2248]	Time  (2.2587433859359387)	Data (0.015789659316357584)	loss  (0.2033502458288424)	Prec1  (93.7188491821289) 	
Training Epoch: [5][400/2248]	Time  (2.2542621584009948)	Data (0.012662973784449095)	loss  (0.20181229210776877)	Prec1  (93.72662353515625) 	
Training Epoch: [5][500/2248]	Time  (2.25225258301832)	Data (0.010703674571480817)	loss  (0.20184621701162017)	Prec1  (93.72037506103516) 	
Training Epoch: [5][600/2248]	Time  (2.250518805572078)	Data (0.009330373040451583)	loss  (0.20222170567899297)	Prec1  (93.71620178222656) 	
Training Epoch: [5][700/2248]	Time  (2.249014408204083)	Data (0.008236428980480418)	loss  (0.20026748438236888)	Prec1  (93.7856674194336) 	
Training Epoch: [5][800/2248]	Time  (2.24754425678658)	Data (0.007337524649802219)	loss  (0.19890008953291824)	Prec1  (93.82119750976562) 	
Training Epoch: [5][900/2248]	Time  (2.2463685341601103)	Data (0.00684581268640787)	loss  (0.1960221275306833)	Prec1  (93.90521240234375) 	
Training Epoch: [5][1000/2248]	Time  (2.2455003735545156)	Data (0.006384188835913842)	loss  (0.1952166828018921)	Prec1  (93.93418884277344) 	
Training Epoch: [5][1100/2248]	Time  (2.2446981611087256)	Data (0.006052459618051305)	loss  (0.19538197296246088)	Prec1  (93.93236541748047) 	
Training Epoch: [5][1200/2248]	Time  (2.2443260838844497)	Data (0.005753430796106292)	loss  (0.19525934712376622)	Prec1  (93.94124603271484) 	
Training Epoch: [5][1300/2248]	Time  (2.244032095616639)	Data (0.005503310321570359)	loss  (0.19305345306400606)	Prec1  (94.01602172851562) 	
Training Epoch: [5][1400/2248]	Time  (2.2436868671346444)	Data (0.005234357036070514)	loss  (0.19127850838372487)	Prec1  (94.07119750976562) 	
Training Epoch: [5][1500/2248]	Time  (2.2438756349005753)	Data (0.005061904721701645)	loss  (0.1912451771166744)	Prec1  (94.07843017578125) 	
Training Epoch: [5][1600/2248]	Time  (2.2437162962204065)	Data (0.0049217153831543885)	loss  (0.19033518969444913)	Prec1  (94.1062240600586) 	
Training Epoch: [5][1700/2248]	Time  (2.2434822862671098)	Data (0.0047927987638604706)	loss  (0.1902454481654522)	Prec1  (94.09492492675781) 	
Training Epoch: [5][1800/2248]	Time  (2.2434625653410407)	Data (0.004681952194264701)	loss  (0.18977122859143006)	Prec1  (94.12348937988281) 	
Training Epoch: [5][1900/2248]	Time  (2.243680773378359)	Data (0.004575327156343816)	loss  (0.18879075921182253)	Prec1  (94.15562438964844) 	
Training Epoch: [5][2000/2248]	Time  (2.2440782426179258)	Data (0.0044623244589176965)	loss  (0.18713580090729431)	Prec1  (94.2009506225586) 	
Training Epoch: [5][2100/2248]	Time  (2.2442350572543392)	Data (0.004319355409523239)	loss  (0.18612552819501382)	Prec1  (94.22819519042969) 	
Training Epoch: [5][2200/2248]	Time  (2.244519819838521)	Data (0.004239985532296998)	loss  (0.18549975574267066)	Prec1  (94.24622344970703) 	
Testing Epoch: [5][0/32]	Time  (3.861180305480957)	Data (3.0294556617736816)	loss  (1.8835197687149048)	Prec1  (60.9375) 	
Testing Epoch: [5][31/32]	Time  (0.665527269244194)	Data (0.09474269300699234)	loss  (2.5179703102111817)	Prec1  (52.150001525878906) 	
Epoch: 5   Test Acc: 52.150001525878906

******************************
	Adjusted learning rate: 6

0.0007350918906249997
Training Epoch: [6][0/2248]	Time  (6.121081352233887)	Data (3.664592742919922)	loss  (0.16052696108818054)	Prec1  (93.75) 	
Training Epoch: [6][100/2248]	Time  (2.2831215575189874)	Data (0.038461390108165176)	loss  (0.17087466550050395)	Prec1  (94.69368743896484) 	
Training Epoch: [6][200/2248]	Time  (2.2636303818641017)	Data (0.020416454296206952)	loss  (0.1672411164018645)	Prec1  (94.65951538085938) 	
Training Epoch: [6][300/2248]	Time  (2.256143237269202)	Data (0.014370729756909747)	loss  (0.16643221520407256)	Prec1  (94.68698120117188) 	
Training Epoch: [6][400/2248]	Time  (2.253367192132812)	Data (0.011417314001449623)	loss  (0.16666161453820524)	Prec1  (94.73971557617188) 	
Training Epoch: [6][500/2248]	Time  (2.2515601678760704)	Data (0.009603974348056816)	loss  (0.16849674480017313)	Prec1  (94.71525573730469) 	
Training Epoch: [6][600/2248]	Time  (2.2509209645568036)	Data (0.008478056372897993)	loss  (0.16779338366998214)	Prec1  (94.74443054199219) 	
Training Epoch: [6][700/2248]	Time  (2.2499745837631986)	Data (0.007717016250022638)	loss  (0.16757365596213628)	Prec1  (94.77643585205078) 	
Training Epoch: [6][800/2248]	Time  (2.2491442398185586)	Data (0.007147905383068375)	loss  (0.16571157161941688)	Prec1  (94.8433609008789) 	
Training Epoch: [6][900/2248]	Time  (2.2488404701605487)	Data (0.006544066586849031)	loss  (0.1637613090307149)	Prec1  (94.90843963623047) 	
Training Epoch: [6][1000/2248]	Time  (2.248657273007678)	Data (0.006126558864033306)	loss  (0.16377147303505257)	Prec1  (94.90353393554688) 	
Training Epoch: [6][1100/2248]	Time  (2.248210435558946)	Data (0.005783788514721945)	loss  (0.16173998993245392)	Prec1  (94.97828674316406) 	
Training Epoch: [6][1200/2248]	Time  (2.248154516521838)	Data (0.005512317154032304)	loss  (0.1607588998241339)	Prec1  (95.00806427001953) 	
Training Epoch: [6][1300/2248]	Time  (2.2480017752211245)	Data (0.005307802688516533)	loss  (0.15950385657218583)	Prec1  (95.0386734008789) 	
Training Epoch: [6][1400/2248]	Time  (2.247922058534316)	Data (0.0050966024909336)	loss  (0.15836141700141776)	Prec1  (95.07605743408203) 	
Training Epoch: [6][1500/2248]	Time  (2.247800493621572)	Data (0.004906254399227826)	loss  (0.15822436273604293)	Prec1  (95.07984161376953) 	
Training Epoch: [6][1600/2248]	Time  (2.2473665409576586)	Data (0.004757506634428083)	loss  (0.1574625512939889)	Prec1  (95.1197509765625) 	
Training Epoch: [6][1700/2248]	Time  (2.247683362915963)	Data (0.004648836551870338)	loss  (0.15702658492430108)	Prec1  (95.14209747314453) 	
Training Epoch: [6][1800/2248]	Time  (2.247601425694069)	Data (0.004512945193174744)	loss  (0.1561514832191107)	Prec1  (95.17151641845703) 	
Training Epoch: [6][1900/2248]	Time  (2.24742750805469)	Data (0.004366443635036543)	loss  (0.15535718063455956)	Prec1  (95.2035903930664) 	
Training Epoch: [6][2000/2248]	Time  (2.247343956381604)	Data (0.004271019940850497)	loss  (0.1548538248332544)	Prec1  (95.23558807373047) 	
Training Epoch: [6][2100/2248]	Time  (2.247360692598433)	Data (0.004176394591043246)	loss  (0.15422508095536047)	Prec1  (95.26342010498047) 	
Training Epoch: [6][2200/2248]	Time  (2.2473994104063872)	Data (0.004109835743849952)	loss  (0.15362618116493498)	Prec1  (95.28375244140625) 	
Testing Epoch: [6][0/32]	Time  (4.073199987411499)	Data (3.19232177734375)	loss  (2.323256015777588)	Prec1  (57.03125) 	
Testing Epoch: [6][31/32]	Time  (0.6773925498127937)	Data (0.09983798116445541)	loss  (2.904267688751221)	Prec1  (50.150001525878906) 	
Epoch: 6   Test Acc: 50.150001525878906

******************************
	Adjusted learning rate: 7

0.0006983372960937497
Training Epoch: [7][0/2248]	Time  (5.7302610874176025)	Data (3.295461654663086)	loss  (0.1301048994064331)	Prec1  (96.875) 	
Training Epoch: [7][100/2248]	Time  (2.290031924106107)	Data (0.034716773741316084)	loss  (0.131140437530409)	Prec1  (95.93904876708984) 	
Training Epoch: [7][200/2248]	Time  (2.2710608415935765)	Data (0.018626209515244213)	loss  (0.13346897328819207)	Prec1  (96.03155517578125) 	
Training Epoch: [7][300/2248]	Time  (2.2636910427448362)	Data (0.013339349993835651)	loss  (0.1349403517834372)	Prec1  (95.98733520507812) 	
Training Epoch: [7][400/2248]	Time  (2.260051981172062)	Data (0.010700988056059194)	loss  (0.1334537035434918)	Prec1  (95.998291015625) 	
Training Epoch: [7][500/2248]	Time  (2.258224191779862)	Data (0.009225737786816504)	loss  (0.13528724365724537)	Prec1  (95.90506744384766) 	
Training Epoch: [7][600/2248]	Time  (2.2541456337578087)	Data (0.00818922238024618)	loss  (0.1361834426873833)	Prec1  (95.88835906982422) 	
Training Epoch: [7][700/2248]	Time  (2.2509434199367204)	Data (0.007227980631394325)	loss  (0.13636468711724975)	Prec1  (95.88311767578125) 	
Training Epoch: [7][800/2248]	Time  (2.248723169391075)	Data (0.00662769926025924)	loss  (0.1348650052250548)	Prec1  (95.90258026123047) 	
Training Epoch: [7][900/2248]	Time  (2.246574823123369)	Data (0.006151356787051795)	loss  (0.13424223759826623)	Prec1  (95.92466735839844) 	
Training Epoch: [7][1000/2248]	Time  (2.2447585247375152)	Data (0.005770001616273131)	loss  (0.13414955528064088)	Prec1  (95.92984771728516) 	
Training Epoch: [7][1100/2248]	Time  (2.2432286960227614)	Data (0.005459334393396473)	loss  (0.13338347629294625)	Prec1  (95.95396423339844) 	
Training Epoch: [7][1200/2248]	Time  (2.242013166389497)	Data (0.005163947906621192)	loss  (0.1327561401233983)	Prec1  (95.98056030273438) 	
Training Epoch: [7][1300/2248]	Time  (2.241175499446203)	Data (0.004898755024434235)	loss  (0.13305443472627673)	Prec1  (95.97544860839844) 	
Training Epoch: [7][1400/2248]	Time  (2.2405174574964306)	Data (0.0046569564187637314)	loss  (0.132186573578429)	Prec1  (96.00173950195312) 	
Training Epoch: [7][1500/2248]	Time  (2.2397557311976137)	Data (0.004496711639465291)	loss  (0.13217191054900831)	Prec1  (96.0052719116211) 	
Training Epoch: [7][1600/2248]	Time  (2.2391690881754145)	Data (0.004334136890218379)	loss  (0.13225088913521865)	Prec1  (96.01763153076172) 	
Training Epoch: [7][1700/2248]	Time  (2.2386131191309726)	Data (0.004133375724016534)	loss  (0.13210427894452473)	Prec1  (96.02577209472656) 	
Training Epoch: [7][1800/2248]	Time  (2.2378362321244682)	Data (0.004020345402981823)	loss  (0.13167812503762605)	Prec1  (96.033447265625) 	
Training Epoch: [7][1900/2248]	Time  (2.2387580803856606)	Data (0.0039315276369178125)	loss  (0.13143325479664908)	Prec1  (96.04977416992188) 	
Training Epoch: [7][2000/2248]	Time  (2.2381395944531475)	Data (0.0038498540570413037)	loss  (0.13109985573858635)	Prec1  (96.05821990966797) 	
Training Epoch: [7][2100/2248]	Time  (2.2381181334496)	Data (0.00378697772981552)	loss  (0.1304216470067584)	Prec1  (96.07999420166016) 	
Training Epoch: [7][2200/2248]	Time  (2.2378077998804753)	Data (0.003724181397510409)	loss  (0.13058527595431682)	Prec1  (96.08380889892578) 	
Testing Epoch: [7][0/32]	Time  (4.588054180145264)	Data (3.5206830501556396)	loss  (2.5475966930389404)	Prec1  (55.46875) 	
Testing Epoch: [7][31/32]	Time  (0.6582750305533409)	Data (0.11008431017398834)	loss  (3.223431915283203)	Prec1  (49.80000305175781) 	
Epoch: 7   Test Acc: 49.80000305175781

******************************
	Adjusted learning rate: 8

0.0006634204312890621
Training Epoch: [8][0/2248]	Time  (6.269376754760742)	Data (3.5654091835021973)	loss  (0.09481282532215118)	Prec1  (95.3125) 	
Training Epoch: [8][100/2248]	Time  (2.269509756919181)	Data (0.03754931865352215)	loss  (0.12527919737714352)	Prec1  (96.2252426147461) 	
Training Epoch: [8][200/2248]	Time  (2.253166873656695)	Data (0.020115731367424353)	loss  (0.1187017901582801)	Prec1  (96.4552230834961) 	
Training Epoch: [8][300/2248]	Time  (2.247932517251303)	Data (0.014152320120421755)	loss  (0.11876866643462466)	Prec1  (96.49345397949219) 	
Training Epoch: [8][400/2248]	Time  (2.24585597473487)	Data (0.011134845657538892)	loss  (0.11720753575389523)	Prec1  (96.52042388916016) 	
Training Epoch: [8][500/2248]	Time  (2.2488056461730164)	Data (0.009407882918854674)	loss  (0.11708085505875523)	Prec1  (96.54129028320312) 	
Training Epoch: [8][600/2248]	Time  (2.2451798118489754)	Data (0.008205510217219145)	loss  (0.11699029701001037)	Prec1  (96.52532196044922) 	
Training Epoch: [8][700/2248]	Time  (2.243355820080353)	Data (0.007381769457829322)	loss  (0.11609037820457052)	Prec1  (96.5328598022461) 	
Training Epoch: [8][800/2248]	Time  (2.2427710540285717)	Data (0.006585492325781585)	loss  (0.11627932514218653)	Prec1  (96.55703735351562) 	
Training Epoch: [8][900/2248]	Time  (2.2426127336927575)	Data (0.006118178764538019)	loss  (0.11456567330180474)	Prec1  (96.5975341796875) 	
Training Epoch: [8][1000/2248]	Time  (2.241845657537272)	Data (0.005747641954984103)	loss  (0.11422860117761287)	Prec1  (96.6057357788086) 	
Training Epoch: [8][1100/2248]	Time  (2.24100439381751)	Data (0.005440698116070351)	loss  (0.11395477807719419)	Prec1  (96.62310028076172) 	
Training Epoch: [8][1200/2248]	Time  (2.2399305707707593)	Data (0.005190771882678944)	loss  (0.11396813464601471)	Prec1  (96.61740112304688) 	
Training Epoch: [8][1300/2248]	Time  (2.238775086347916)	Data (0.0049678934802466585)	loss  (0.11348310129274597)	Prec1  (96.63719940185547) 	
Training Epoch: [8][1400/2248]	Time  (2.2376633946339117)	Data (0.004733889720679861)	loss  (0.11293092948370623)	Prec1  (96.65361785888672) 	
Training Epoch: [8][1500/2248]	Time  (2.2368272392849855)	Data (0.004568241025351589)	loss  (0.11243755019193566)	Prec1  (96.68138122558594) 	
Training Epoch: [8][1600/2248]	Time  (2.236326647430267)	Data (0.004432813887444233)	loss  (0.1123437979104443)	Prec1  (96.6871337890625) 	
Training Epoch: [8][1700/2248]	Time  (2.2363358098993857)	Data (0.0043117653825996485)	loss  (0.11191844008534463)	Prec1  (96.70413970947266) 	
Training Epoch: [8][1800/2248]	Time  (2.236084953273157)	Data (0.004201633807091763)	loss  (0.11117392470817113)	Prec1  (96.72403717041016) 	
Training Epoch: [8][1900/2248]	Time  (2.23568076237072)	Data (0.004061922156641447)	loss  (0.11129155754847066)	Prec1  (96.71965789794922) 	
Training Epoch: [8][2000/2248]	Time  (2.235430323201856)	Data (0.003972919507958423)	loss  (0.11098915004524691)	Prec1  (96.7293701171875) 	
Training Epoch: [8][2100/2248]	Time  (2.2351917420495755)	Data (0.0039028413292341493)	loss  (0.11034112600968714)	Prec1  (96.74968719482422) 	
Training Epoch: [8][2200/2248]	Time  (2.2352836351944934)	Data (0.0038343472461275815)	loss  (0.11042473643090658)	Prec1  (96.74259948730469) 	
Testing Epoch: [8][0/32]	Time  (3.8660573959350586)	Data (2.8064334392547607)	loss  (2.8830153942108154)	Prec1  (59.375) 	
Testing Epoch: [8][31/32]	Time  (0.6424909234046936)	Data (0.08777336031198502)	loss  (3.711748649597168)	Prec1  (48.375003814697266) 	
Epoch: 8   Test Acc: 48.375003814697266

******************************
	Adjusted learning rate: 9

0.000630249409724609
Training Epoch: [9][0/2248]	Time  (5.713329315185547)	Data (3.0637755393981934)	loss  (0.05649257451295853)	Prec1  (97.65625) 	
Training Epoch: [9][100/2248]	Time  (2.2696171042942765)	Data (0.03251370581069795)	loss  (0.09974301731822514)	Prec1  (97.12252044677734) 	
Training Epoch: [9][200/2248]	Time  (2.2470041685436497)	Data (0.017392850040796385)	loss  (0.09761581690379637)	Prec1  (97.15873718261719) 	
Training Epoch: [9][300/2248]	Time  (2.2386792355597613)	Data (0.012408603465438286)	loss  (0.09754727170663419)	Prec1  (97.19424438476562) 	
Training Epoch: [9][400/2248]	Time  (2.234006592163124)	Data (0.00974564778239947)	loss  (0.09661166893871051)	Prec1  (97.23738098144531) 	
Training Epoch: [9][500/2248]	Time  (2.233662737105897)	Data (0.008256226480602029)	loss  (0.09839192254398159)	Prec1  (97.15880584716797) 	
Training Epoch: [9][600/2248]	Time  (2.2340507281203434)	Data (0.007235356852932896)	loss  (0.09941318968989686)	Prec1  (97.12068176269531) 	
Training Epoch: [9][700/2248]	Time  (2.23408624619118)	Data (0.006441100347739314)	loss  (0.09902878730596387)	Prec1  (97.14693450927734) 	
Training Epoch: [9][800/2248]	Time  (2.2333861900477223)	Data (0.0058200701643316335)	loss  (0.09852312842428164)	Prec1  (97.17443084716797) 	
Training Epoch: [9][900/2248]	Time  (2.2333369202142817)	Data (0.005446698107280159)	loss  (0.09805448135396219)	Prec1  (97.17675018310547) 	
Training Epoch: [9][1000/2248]	Time  (2.2376135041068244)	Data (0.005179096768786024)	loss  (0.09811647603666032)	Prec1  (97.17235565185547) 	
Training Epoch: [9][1100/2248]	Time  (2.240162603645082)	Data (0.004959876704064421)	loss  (0.09850220005285945)	Prec1  (97.1602554321289) 	
Training Epoch: [9][1200/2248]	Time  (2.2424899672191407)	Data (0.004748789495869938)	loss  (0.09893320344828944)	Prec1  (97.15145874023438) 	
Training Epoch: [9][1300/2248]	Time  (2.2441561093795857)	Data (0.004589443661266799)	loss  (0.0989003306473795)	Prec1  (97.15122985839844) 	
Training Epoch: [9][1400/2248]	Time  (2.245882085525164)	Data (0.004376842157063018)	loss  (0.0987703833891229)	Prec1  (97.1409912109375) 	
Training Epoch: [9][1500/2248]	Time  (2.247585112217821)	Data (0.004219725638687571)	loss  (0.09799384673701216)	Prec1  (97.16127014160156) 	
Training Epoch: [9][1600/2248]	Time  (2.249252991554217)	Data (0.004099401960069131)	loss  (0.09726306941036802)	Prec1  (97.18682098388672) 	
Training Epoch: [9][1700/2248]	Time  (2.250297381694285)	Data (0.003999914441789899)	loss  (0.09735025241664408)	Prec1  (97.188232421875) 	
Training Epoch: [9][1800/2248]	Time  (2.251981353706813)	Data (0.003906027864311087)	loss  (0.09730232022557903)	Prec1  (97.19947052001953) 	
Training Epoch: [9][1900/2248]	Time  (2.25329686227063)	Data (0.0038215493227794634)	loss  (0.09655477096185065)	Prec1  (97.21610260009766) 	
Training Epoch: [9][2000/2248]	Time  (2.2546783039297003)	Data (0.0037502670574045254)	loss  (0.09611865169536704)	Prec1  (97.22248840332031) 	
Training Epoch: [9][2100/2248]	Time  (2.2549647439496394)	Data (0.0036846758467080987)	loss  (0.09606400011430917)	Prec1  (97.2226791381836) 	
Training Epoch: [9][2200/2248]	Time  (2.2539195058996815)	Data (0.0036238034927319634)	loss  (0.0957527902960669)	Prec1  (97.22640228271484) 	
Testing Epoch: [9][0/32]	Time  (4.015680551528931)	Data (2.8032636642456055)	loss  (2.653719902038574)	Prec1  (57.03125) 	
Testing Epoch: [9][31/32]	Time  (0.6487110108137131)	Data (0.08766764402389526)	loss  (3.3925900535583495)	Prec1  (47.900001525878906) 	
Epoch: 9   Test Acc: 47.900001525878906

******************************
	Adjusted learning rate: 10

0.0005987369392383785
Training Epoch: [10][0/2248]	Time  (7.141318082809448)	Data (4.342170000076294)	loss  (0.08645091950893402)	Prec1  (97.65625) 	
Training Epoch: [10][100/2248]	Time  (2.2795658866957864)	Data (0.045347079192057695)	loss  (0.09080546581656626)	Prec1  (97.4241943359375) 	
Training Epoch: [10][200/2248]	Time  (2.2553207530311092)	Data (0.024251342412844226)	loss  (0.08869839726544138)	Prec1  (97.55130004882812) 	
Training Epoch: [10][300/2248]	Time  (2.2479419834986083)	Data (0.017332257622500194)	loss  (0.08616803579675993)	Prec1  (97.60433959960938) 	
Training Epoch: [10][400/2248]	Time  (2.2440124194223685)	Data (0.013832337838455923)	loss  (0.0875668740016118)	Prec1  (97.560791015625) 	
Training Epoch: [10][500/2248]	Time  (2.24234242829496)	Data (0.011716437197017099)	loss  (0.08778990615538494)	Prec1  (97.52214050292969) 	
Training Epoch: [10][600/2248]	Time  (2.2439064955751036)	Data (0.010015082240303027)	loss  (0.08685044582604667)	Prec1  (97.54185485839844) 	
Training Epoch: [10][700/2248]	Time  (2.241965743512468)	Data (0.008948614185784921)	loss  (0.08879879756582192)	Prec1  (97.47236633300781) 	
Training Epoch: [10][800/2248]	Time  (2.240665754873059)	Data (0.008152578951565365)	loss  (0.08861536636120743)	Prec1  (97.48848724365234) 	
Training Epoch: [10][900/2248]	Time  (2.2391569664687347)	Data (0.007543248421079443)	loss  (0.0884263649041228)	Prec1  (97.48370361328125) 	
Training Epoch: [10][1000/2248]	Time  (2.2380163367097077)	Data (0.007006987706050054)	loss  (0.08749081643780211)	Prec1  (97.50639343261719) 	
Training Epoch: [10][1100/2248]	Time  (2.236835040145306)	Data (0.006537388282727373)	loss  (0.08710091755464064)	Prec1  (97.52001190185547) 	
Training Epoch: [10][1200/2248]	Time  (2.2403516017030816)	Data (0.006158340582740396)	loss  (0.08642607911658177)	Prec1  (97.5261459350586) 	
Training Epoch: [10][1300/2248]	Time  (2.246633832221944)	Data (0.00587638243631983)	loss  (0.08641947071704381)	Prec1  (97.52533721923828) 	
Training Epoch: [10][1400/2248]	Time  (2.245950151561925)	Data (0.005655228453478925)	loss  (0.0867834211826367)	Prec1  (97.512939453125) 	
Training Epoch: [10][1500/2248]	Time  (2.2445924191535274)	Data (0.005458536027353021)	loss  (0.08643118155962583)	Prec1  (97.53653717041016) 	
Training Epoch: [10][1600/2248]	Time  (2.2435240477491067)	Data (0.005270059223401405)	loss  (0.08629216098207411)	Prec1  (97.54255676269531) 	
Training Epoch: [10][1700/2248]	Time  (2.2424255988655335)	Data (0.0050656080666463)	loss  (0.0863574414751079)	Prec1  (97.53913116455078) 	
Training Epoch: [10][1800/2248]	Time  (2.2410182967442793)	Data (0.00491668806017802)	loss  (0.08583535418754185)	Prec1  (97.55517578125) 	
Training Epoch: [10][1900/2248]	Time  (2.2399644551936855)	Data (0.0047697743762486365)	loss  (0.086182160679249)	Prec1  (97.54981231689453) 	
Training Epoch: [10][2000/2248]	Time  (2.24277996921587)	Data (0.004648186575466845)	loss  (0.08555570628953868)	Prec1  (97.5672378540039) 	
Training Epoch: [10][2100/2248]	Time  (2.2414885964182547)	Data (0.00454983241441192)	loss  (0.0852092467886757)	Prec1  (97.57369995117188) 	
Training Epoch: [10][2200/2248]	Time  (2.240359967104796)	Data (0.0043928902672399775)	loss  (0.08506402895717743)	Prec1  (97.58135223388672) 	
Testing Epoch: [10][0/32]	Time  (4.403196811676025)	Data (3.1622583866119385)	loss  (2.580681324005127)	Prec1  (54.6875) 	
Testing Epoch: [10][31/32]	Time  (0.6578060984611511)	Data (0.09889056533575058)	loss  (3.3058391914367675)	Prec1  (48.92500305175781) 	
Epoch: 10   Test Acc: 48.92500305175781

******************************
	Adjusted learning rate: 11

0.0005688000922764595
Training Epoch: [11][0/2248]	Time  (7.171048641204834)	Data (3.9310996532440186)	loss  (0.11246264725923538)	Prec1  (96.875) 	
Training Epoch: [11][100/2248]	Time  (2.2788891792297363)	Data (0.041631460189819336)	loss  (0.07505588491659353)	Prec1  (97.7877426147461) 	
Training Epoch: [11][200/2248]	Time  (2.253534460542214)	Data (0.02224867735336076)	loss  (0.07611533258091752)	Prec1  (97.77674102783203) 	
Training Epoch: [11][300/2248]	Time  (2.248978318566104)	Data (0.015842756955726598)	loss  (0.07636467950338145)	Prec1  (97.8145751953125) 	
Training Epoch: [11][400/2248]	Time  (2.2474739272100965)	Data (0.0126640535054956)	loss  (0.07675220825224)	Prec1  (97.83744049072266) 	
Training Epoch: [11][500/2248]	Time  (2.2467942728015955)	Data (0.010643755366464338)	loss  (0.07674373364719207)	Prec1  (97.8277816772461) 	
Training Epoch: [11][600/2248]	Time  (2.2505279670340843)	Data (0.009387672840061282)	loss  (0.07708806275837929)	Prec1  (97.8109359741211) 	
Training Epoch: [11][700/2248]	Time  (2.2522697360301325)	Data (0.008466779420447247)	loss  (0.07695009721211887)	Prec1  (97.81673431396484) 	
Training Epoch: [11][800/2248]	Time  (2.254148343677973)	Data (0.007764149247930291)	loss  (0.07718309992401118)	Prec1  (97.79962158203125) 	
Training Epoch: [11][900/2248]	Time  (2.253890942257067)	Data (0.007229836217306562)	loss  (0.07723146548223879)	Prec1  (97.80625915527344) 	
Training Epoch: [11][1000/2248]	Time  (2.2524096787154497)	Data (0.006749319387125326)	loss  (0.07674819804713146)	Prec1  (97.81936645507812) 	
Training Epoch: [11][1100/2248]	Time  (2.2529154577437147)	Data (0.006388034742599612)	loss  (0.07659645466223616)	Prec1  (97.82442474365234) 	
Training Epoch: [11][1200/2248]	Time  (2.2529139707328674)	Data (0.006104602901068059)	loss  (0.07644789785357638)	Prec1  (97.83838653564453) 	
Training Epoch: [11][1300/2248]	Time  (2.2517743717240517)	Data (0.005816376273399312)	loss  (0.07631952905716757)	Prec1  (97.84239959716797) 	
Training Epoch: [11][1400/2248]	Time  (2.2505655528646464)	Data (0.0055715481270048805)	loss  (0.07595237876041969)	Prec1  (97.84305572509766) 	
Training Epoch: [11][1500/2248]	Time  (2.2506739430869125)	Data (0.005363371751850085)	loss  (0.07610654635857456)	Prec1  (97.83529663085938) 	
Training Epoch: [11][1600/2248]	Time  (2.250952463161938)	Data (0.005199919634502728)	loss  (0.07598679368707033)	Prec1  (97.84705352783203) 	
Training Epoch: [11][1700/2248]	Time  (2.2516422273130154)	Data (0.0050436386565893)	loss  (0.07557880011075634)	Prec1  (97.85649871826172) 	
Training Epoch: [11][1800/2248]	Time  (2.25194023212812)	Data (0.004850018229635472)	loss  (0.0753773284309659)	Prec1  (97.85926055908203) 	
Training Epoch: [11][1900/2248]	Time  (2.2520097805787738)	Data (0.004702740879450141)	loss  (0.07514718866788012)	Prec1  (97.87077331542969) 	
Training Epoch: [11][2000/2248]	Time  (2.2517397982784653)	Data (0.004599420384488542)	loss  (0.07476114302962973)	Prec1  (97.88387298583984) 	
Training Epoch: [11][2100/2248]	Time  (2.251632112936994)	Data (0.00450318612012904)	loss  (0.07485173947431824)	Prec1  (97.87973022460938) 	
Training Epoch: [11][2200/2248]	Time  (2.253993976771534)	Data (0.004409265539853045)	loss  (0.07470810299113846)	Prec1  (97.88377380371094) 	
Testing Epoch: [11][0/32]	Time  (13.807690143585205)	Data (13.008769750595093)	loss  (2.873077154159546)	Prec1  (57.8125) 	
Testing Epoch: [11][31/32]	Time  (1.1514203622937202)	Data (0.5732164680957794)	loss  (3.5770798988342287)	Prec1  (48.85000228881836) 	
Epoch: 11   Test Acc: 48.85000228881836

******************************
	Adjusted learning rate: 12

0.0005403600876626365
Training Epoch: [12][0/2248]	Time  (7.963548183441162)	Data (5.547342300415039)	loss  (0.06439979374408722)	Prec1  (97.65625) 	
Training Epoch: [12][100/2248]	Time  (2.3191774882892573)	Data (0.05782694863800955)	loss  (0.07459913808299173)	Prec1  (97.72586822509766) 	
Training Epoch: [12][200/2248]	Time  (2.289462689736589)	Data (0.030278801324948743)	loss  (0.07301197527208138)	Prec1  (97.83892822265625) 	
Training Epoch: [12][300/2248]	Time  (2.278868244335897)	Data (0.020755105636444598)	loss  (0.07328126672345935)	Prec1  (97.874267578125) 	
Training Epoch: [12][400/2248]	Time  (2.27697816335055)	Data (0.01619368301068161)	loss  (0.07170996401096669)	Prec1  (97.91926574707031) 	
Training Epoch: [12][500/2248]	Time  (2.2766939575324754)	Data (0.013452532762538888)	loss  (0.07213692585314938)	Prec1  (97.926025390625) 	
Training Epoch: [12][600/2248]	Time  (2.2732169481363154)	Data (0.01162340438703134)	loss  (0.07144952735580046)	Prec1  (97.92662811279297) 	
Training Epoch: [12][700/2248]	Time  (2.270589323424749)	Data (0.010304672741855942)	loss  (0.07013668843974145)	Prec1  (97.96050262451172) 	
Training Epoch: [12][800/2248]	Time  (2.2681578053963767)	Data (0.00929329487566049)	loss  (0.06931056629880314)	Prec1  (98.00932312011719) 	
Training Epoch: [12][900/2248]	Time  (2.2666786399718526)	Data (0.00852957840897267)	loss  (0.06964582443592882)	Prec1  (97.99268341064453) 	
Training Epoch: [12][1000/2248]	Time  (2.2653747912529822)	Data (0.007890817525979879)	loss  (0.06922031524633016)	Prec1  (98.0168228149414) 	
Training Epoch: [12][1100/2248]	Time  (2.264664425403827)	Data (0.007392162198266801)	loss  (0.06920170320450014)	Prec1  (98.0167236328125) 	
Training Epoch: [12][1200/2248]	Time  (2.263580212287363)	Data (0.006974871013682649)	loss  (0.06873921510747182)	Prec1  (98.0218276977539) 	
Training Epoch: [12][1300/2248]	Time  (2.2657713283491905)	Data (0.0065653483561604505)	loss  (0.06865106324316629)	Prec1  (98.03276062011719) 	
Training Epoch: [12][1400/2248]	Time  (2.265148020743643)	Data (0.006189191962547765)	loss  (0.06807505233156136)	Prec1  (98.04714965820312) 	
Training Epoch: [12][1500/2248]	Time  (2.263502756172145)	Data (0.0059171704591551594)	loss  (0.06777139600344018)	Prec1  (98.06327056884766) 	
Training Epoch: [12][1600/2248]	Time  (2.2620890690042854)	Data (0.005640198036255798)	loss  (0.06786418116670671)	Prec1  (98.06664276123047) 	
Training Epoch: [12][1700/2248]	Time  (2.261116263447335)	Data (0.005455857371667215)	loss  (0.06762571432471697)	Prec1  (98.06731414794922) 	
Training Epoch: [12][1800/2248]	Time  (2.2604530135636063)	Data (0.005290307712713789)	loss  (0.06732975630537462)	Prec1  (98.07572174072266) 	
Training Epoch: [12][1900/2248]	Time  (2.259433027445047)	Data (0.005103457920931315)	loss  (0.06706421045113212)	Prec1  (98.0799560546875) 	
Training Epoch: [12][2000/2248]	Time  (2.258981670635096)	Data (0.004953561575039811)	loss  (0.06696195257962614)	Prec1  (98.07752990722656) 	
Training Epoch: [12][2100/2248]	Time  (2.2585943742685806)	Data (0.004816836144230809)	loss  (0.06701041432695977)	Prec1  (98.0842514038086) 	
Training Epoch: [12][2200/2248]	Time  (2.2580549409312587)	Data (0.004704943249194203)	loss  (0.06710428219781119)	Prec1  (98.08077239990234) 	
Testing Epoch: [12][0/32]	Time  (3.9492576122283936)	Data (3.074256181716919)	loss  (2.735461950302124)	Prec1  (57.03125) 	
Testing Epoch: [12][31/32]	Time  (0.6745837703347206)	Data (0.0961410328745842)	loss  (3.48434725189209)	Prec1  (48.67500305175781) 	
Epoch: 12   Test Acc: 48.67500305175781

******************************
	Adjusted learning rate: 13

0.0005133420832795047
Training Epoch: [13][0/2248]	Time  (6.49956202507019)	Data (4.1096460819244385)	loss  (0.23621928691864014)	Prec1  (95.3125) 	
Training Epoch: [13][100/2248]	Time  (2.2860655973453334)	Data (0.04331137166164889)	loss  (0.057814002793171615)	Prec1  (98.37561798095703) 	
Training Epoch: [13][200/2248]	Time  (2.2678217864155177)	Data (0.023237333961980258)	loss  (0.0587137392096555)	Prec1  (98.3442153930664) 	
Training Epoch: [13][300/2248]	Time  (2.2595012433505137)	Data (0.016413651431517743)	loss  (0.06036725377917686)	Prec1  (98.31291198730469) 	
Training Epoch: [13][400/2248]	Time  (2.2535248022721595)	Data (0.012964489454045854)	loss  (0.05945333107804271)	Prec1  (98.30307006835938) 	
Training Epoch: [13][500/2248]	Time  (2.2507520592855124)	Data (0.010752411897548896)	loss  (0.06043084107056825)	Prec1  (98.2909164428711) 	
Training Epoch: [13][600/2248]	Time  (2.2490432151343778)	Data (0.00928826538377911)	loss  (0.06050170250794852)	Prec1  (98.29320526123047) 	
Training Epoch: [13][700/2248]	Time  (2.2469217454145705)	Data (0.008325781529708188)	loss  (0.06052097989068222)	Prec1  (98.29150390625) 	
Training Epoch: [13][800/2248]	Time  (2.246223822663935)	Data (0.007596568073077446)	loss  (0.05998786792540446)	Prec1  (98.30582427978516) 	
Training Epoch: [13][900/2248]	Time  (2.24757552596758)	Data (0.007046760914725283)	loss  (0.06045785233725718)	Prec1  (98.28575897216797) 	
Training Epoch: [13][1000/2248]	Time  (2.2502710221411584)	Data (0.00664383833939498)	loss  (0.060307820382473114)	Prec1  (98.28296661376953) 	
Training Epoch: [13][1100/2248]	Time  (2.2509947947000613)	Data (0.006258463881212836)	loss  (0.06015699018270021)	Prec1  (98.29558563232422) 	
Training Epoch: [13][1200/2248]	Time  (2.250544574040358)	Data (0.0059491216292687004)	loss  (0.0600136502721129)	Prec1  (98.28593444824219) 	
Training Epoch: [13][1300/2248]	Time  (2.2510712383161775)	Data (0.005663111427946332)	loss  (0.06022856980676746)	Prec1  (98.28376770019531) 	
Training Epoch: [13][1400/2248]	Time  (2.25281024047258)	Data (0.00538723848276186)	loss  (0.060057263181868575)	Prec1  (98.2969741821289) 	
Training Epoch: [13][1500/2248]	Time  (2.2549855265912813)	Data (0.0051917297533557545)	loss  (0.05992859237511542)	Prec1  (98.29644775390625) 	
Training Epoch: [13][1600/2248]	Time  (2.255898210571975)	Data (0.005016726601652471)	loss  (0.05998662823135223)	Prec1  (98.29647827148438) 	
Training Epoch: [13][1700/2248]	Time  (2.257405493695339)	Data (0.004851369981132207)	loss  (0.059762640249012566)	Prec1  (98.30843353271484) 	
Training Epoch: [13][1800/2248]	Time  (2.2584108805934435)	Data (0.004741253421281458)	loss  (0.05966892374419855)	Prec1  (98.30996704101562) 	
Training Epoch: [13][1900/2248]	Time  (2.2590098752278145)	Data (0.0046034961672345946)	loss  (0.05947863131365702)	Prec1  (98.32078552246094) 	
Training Epoch: [13][2000/2248]	Time  (2.2597405203934136)	Data (0.004494134215698547)	loss  (0.059237037083950415)	Prec1  (98.32623291015625) 	
Training Epoch: [13][2100/2248]	Time  (2.2598973550664874)	Data (0.004412223474574282)	loss  (0.0590503317796435)	Prec1  (98.3311538696289) 	
Training Epoch: [13][2200/2248]	Time  (2.2602452630619743)	Data (0.004342008102812154)	loss  (0.05917808038945471)	Prec1  (98.32888793945312) 	
Testing Epoch: [13][0/32]	Time  (3.656195640563965)	Data (2.751253604888916)	loss  (2.846245288848877)	Prec1  (60.9375) 	
Testing Epoch: [13][31/32]	Time  (0.6616990640759468)	Data (0.08605416864156723)	loss  (3.6731327781677248)	Prec1  (49.42500305175781) 	
Epoch: 13   Test Acc: 49.42500305175781

******************************
	Adjusted learning rate: 14

0.00048767497911552944
Training Epoch: [14][0/2248]	Time  (5.901554584503174)	Data (3.2125229835510254)	loss  (0.024841640144586563)	Prec1  (99.21875) 	
Training Epoch: [14][100/2248]	Time  (2.3033873775217795)	Data (0.03384724701985274)	loss  (0.05770139433074706)	Prec1  (98.34467315673828) 	
Training Epoch: [14][200/2248]	Time  (2.285670894888503)	Data (0.018447998151257264)	loss  (0.05493778348969879)	Prec1  (98.40251922607422) 	
Training Epoch: [14][300/2248]	Time  (2.2819687781539866)	Data (0.012895943714534721)	loss  (0.05758777429717918)	Prec1  (98.35704040527344) 	
Training Epoch: [14][400/2248]	Time  (2.278528390085311)	Data (0.010357639736070895)	loss  (0.05605170080563671)	Prec1  (98.41606903076172) 	
Training Epoch: [14][500/2248]	Time  (2.275566772072615)	Data (0.008799967413652918)	loss  (0.056518525349909435)	Prec1  (98.39539337158203) 	
Training Epoch: [14][600/2248]	Time  (2.2741845629972945)	Data (0.007766346764842206)	loss  (0.05660142411730452)	Prec1  (98.385498046875) 	
Training Epoch: [14][700/2248]	Time  (2.27245975118901)	Data (0.007074288056682418)	loss  (0.05659043988460056)	Prec1  (98.37620544433594) 	
Training Epoch: [14][800/2248]	Time  (2.2723775115352445)	Data (0.006448390034402949)	loss  (0.05633388075526436)	Prec1  (98.38190460205078) 	
Training Epoch: [14][900/2248]	Time  (2.2710123866564955)	Data (0.0060110327670894375)	loss  (0.056341049586992285)	Prec1  (98.37940979003906) 	
Training Epoch: [14][1000/2248]	Time  (2.2715055394720483)	Data (0.005685252743167477)	loss  (0.05633624246554239)	Prec1  (98.37974548339844) 	
Training Epoch: [14][1100/2248]	Time  (2.2713169707264496)	Data (0.005408339885881443)	loss  (0.05630004256929894)	Prec1  (98.40131378173828) 	
Training Epoch: [14][1200/2248]	Time  (2.271132997033201)	Data (0.005170555734118256)	loss  (0.05627254095024659)	Prec1  (98.39977264404297) 	
Training Epoch: [14][1300/2248]	Time  (2.27040766845017)	Data (0.004983425506896738)	loss  (0.055896770528343714)	Prec1  (98.40386962890625) 	
Training Epoch: [14][1400/2248]	Time  (2.2700391750008952)	Data (0.004752349717373681)	loss  (0.05536862247378208)	Prec1  (98.42411804199219) 	
Training Epoch: [14][1500/2248]	Time  (2.269875084535826)	Data (0.004608761065011021)	loss  (0.05563791211617541)	Prec1  (98.41407775878906) 	
Training Epoch: [14][1600/2248]	Time  (2.2699991572580807)	Data (0.004448507071881649)	loss  (0.05559440575735521)	Prec1  (98.4135971069336) 	
Training Epoch: [14][1700/2248]	Time  (2.270345284755198)	Data (0.004332674173380893)	loss  (0.05543073876347526)	Prec1  (98.4223403930664) 	
Training Epoch: [14][1800/2248]	Time  (2.2703953422088876)	Data (0.00425144171198496)	loss  (0.05542927211060549)	Prec1  (98.41841125488281) 	
Training Epoch: [14][1900/2248]	Time  (2.270787632885511)	Data (0.004167317717028943)	loss  (0.05533845562572105)	Prec1  (98.42229461669922) 	
Training Epoch: [14][2000/2248]	Time  (2.2698325200536025)	Data (0.004082719425390149)	loss  (0.055017427205741556)	Prec1  (98.43281555175781) 	
Training Epoch: [14][2100/2248]	Time  (2.2692112351871003)	Data (0.004006834724640517)	loss  (0.05459125098842828)	Prec1  (98.44010925292969) 	
Training Epoch: [14][2200/2248]	Time  (2.2690772963675085)	Data (0.003912030431911221)	loss  (0.054402764679280964)	Prec1  (98.44744110107422) 	
Testing Epoch: [14][0/32]	Time  (3.8084986209869385)	Data (2.9730772972106934)	loss  (2.5679399967193604)	Prec1  (59.375) 	
Testing Epoch: [14][31/32]	Time  (0.7107328325510025)	Data (0.0929676815867424)	loss  (3.37168758392334)	Prec1  (49.45000076293945) 	
Epoch: 14   Test Acc: 49.45000076293945

******************************
	Adjusted learning rate: 15

0.00046329123015975297
Training Epoch: [15][0/2248]	Time  (5.8305983543396)	Data (3.1333301067352295)	loss  (0.027418352663517)	Prec1  (99.21875) 	
Training Epoch: [15][100/2248]	Time  (2.3015448173674025)	Data (0.032966044869753394)	loss  (0.051297886481527055)	Prec1  (98.50711822509766) 	
Training Epoch: [15][200/2248]	Time  (2.2845628451352096)	Data (0.017895303555388948)	loss  (0.04997657322839125)	Prec1  (98.56964874267578) 	
Training Epoch: [15][300/2248]	Time  (2.2818133640922977)	Data (0.012562545034972537)	loss  (0.04973444757221941)	Prec1  (98.59062957763672) 	
Training Epoch: [15][400/2248]	Time  (2.2770547932222893)	Data (0.010075440727861743)	loss  (0.051322792886647206)	Prec1  (98.56608581542969) 	
Training Epoch: [15][500/2248]	Time  (2.2782391702343605)	Data (0.008399934825783004)	loss  (0.050353726398147745)	Prec1  (98.5840835571289) 	
Training Epoch: [15][600/2248]	Time  (2.2763862026709685)	Data (0.007455819458414037)	loss  (0.05024768644556428)	Prec1  (98.58049011230469) 	
Training Epoch: [15][700/2248]	Time  (2.2754462047582344)	Data (0.006778683369918149)	loss  (0.050548428581886726)	Prec1  (98.56566619873047) 	
Training Epoch: [15][800/2248]	Time  (2.274179212758306)	Data (0.0061765110001581885)	loss  (0.05102095993633351)	Prec1  (98.5516128540039) 	
Training Epoch: [15][900/2248]	Time  (2.2741967290143723)	Data (0.005695595196164012)	loss  (0.05058737013790835)	Prec1  (98.56063079833984) 	
Training Epoch: [15][1000/2248]	Time  (2.2731522539636115)	Data (0.005395961927248167)	loss  (0.050463928047429905)	Prec1  (98.5584716796875) 	
Training Epoch: [15][1100/2248]	Time  (2.2725079529508476)	Data (0.005160614969944759)	loss  (0.049893110707997734)	Prec1  (98.57161712646484) 	
Training Epoch: [15][1200/2248]	Time  (2.272206711431626)	Data (0.0049655149620240376)	loss  (0.05002285368883243)	Prec1  (98.56954956054688) 	
Training Epoch: [15][1300/2248]	Time  (2.273061207493482)	Data (0.004768787211037708)	loss  (0.04992191330869779)	Prec1  (98.56180572509766) 	
Training Epoch: [15][1400/2248]	Time  (2.2727081380853646)	Data (0.004629335260493342)	loss  (0.049899968985391036)	Prec1  (98.5702133178711) 	
Training Epoch: [15][1500/2248]	Time  (2.2723704474040622)	Data (0.004511512810988556)	loss  (0.05000230262079571)	Prec1  (98.5613784790039) 	
Training Epoch: [15][1600/2248]	Time  (2.271562645987821)	Data (0.004403862634500364)	loss  (0.050109490199592766)	Prec1  (98.55901336669922) 	
Training Epoch: [15][1700/2248]	Time  (2.2710549897267356)	Data (0.004311413851855153)	loss  (0.050184996175562754)	Prec1  (98.55828857421875) 	
Training Epoch: [15][1800/2248]	Time  (2.27079624986728)	Data (0.004226233017967517)	loss  (0.05002377045416852)	Prec1  (98.55982208251953) 	
Training Epoch: [15][1900/2248]	Time  (2.2709728093726707)	Data (0.004152466033020501)	loss  (0.04999395476253424)	Prec1  (98.55586242675781) 	
Training Epoch: [15][2000/2248]	Time  (2.2714886926282114)	Data (0.004086831520343649)	loss  (0.04999248995569007)	Prec1  (98.55463409423828) 	
Training Epoch: [15][2100/2248]	Time  (2.271021814359931)	Data (0.003976565891648973)	loss  (0.05001220443347617)	Prec1  (98.55612182617188) 	
Training Epoch: [15][2200/2248]	Time  (2.2705332542863124)	Data (0.003914354065232578)	loss  (0.05011482456650776)	Prec1  (98.55179595947266) 	
Testing Epoch: [15][0/32]	Time  (3.7744224071502686)	Data (2.845153570175171)	loss  (2.590427875518799)	Prec1  (60.9375) 	
Testing Epoch: [15][31/32]	Time  (0.6866423115134239)	Data (0.08899173140525818)	loss  (3.40895471572876)	Prec1  (49.17500305175781) 	
Epoch: 15   Test Acc: 49.17500305175781

******************************
	Adjusted learning rate: 16

0.0004401266686517653
Training Epoch: [16][0/2248]	Time  (5.7587268352508545)	Data (3.321622371673584)	loss  (0.020902827382087708)	Prec1  (99.21875) 	
Training Epoch: [16][100/2248]	Time  (2.3254029325919574)	Data (0.03576439442020832)	loss  (0.048930004109988115)	Prec1  (98.64634704589844) 	
Training Epoch: [16][200/2248]	Time  (2.297721811787999)	Data (0.018937603158144214)	loss  (0.04558286346050341)	Prec1  (98.65904998779297) 	
Training Epoch: [16][300/2248]	Time  (2.289451843084291)	Data (0.013366747536136462)	loss  (0.04663186204121556)	Prec1  (98.65292358398438) 	
Training Epoch: [16][400/2248]	Time  (2.2836611080645324)	Data (0.010584613034255487)	loss  (0.04830186632914733)	Prec1  (98.61869049072266) 	
Training Epoch: [16][500/2248]	Time  (2.280714374340461)	Data (0.009105363529837297)	loss  (0.0481284840474883)	Prec1  (98.63397979736328) 	
Training Epoch: [16][600/2248]	Time  (2.2787766992153227)	Data (0.008042644541989547)	loss  (0.04823480152250725)	Prec1  (98.60648345947266) 	
Training Epoch: [16][700/2248]	Time  (2.277321276753163)	Data (0.0073332225375100655)	loss  (0.04764552092639339)	Prec1  (98.63587951660156) 	
Training Epoch: [16][800/2248]	Time  (2.275967817627982)	Data (0.006701662596989511)	loss  (0.04713425258367547)	Prec1  (98.64036560058594) 	
Training Epoch: [16][900/2248]	Time  (2.27567397026587)	Data (0.006293702734165001)	loss  (0.046199011611240556)	Prec1  (98.6742172241211) 	
Training Epoch: [16][1000/2248]	Time  (2.2750490385812)	Data (0.005889094911969744)	loss  (0.04531430052249105)	Prec1  (98.6989517211914) 	
Training Epoch: [16][1100/2248]	Time  (2.27487628293189)	Data (0.005613921665257481)	loss  (0.04515016135792641)	Prec1  (98.70714569091797) 	
Training Epoch: [16][1200/2248]	Time  (2.2752064052569083)	Data (0.005302387510707833)	loss  (0.04496610635499176)	Prec1  (98.70550537109375) 	
Training Epoch: [16][1300/2248]	Time  (2.274707802985834)	Data (0.005096200060422928)	loss  (0.045091945274255536)	Prec1  (98.69571685791016) 	
Training Epoch: [16][1400/2248]	Time  (2.2742516298450632)	Data (0.004890966721724647)	loss  (0.04495510421454013)	Prec1  (98.6995849609375) 	
Training Epoch: [16][1500/2248]	Time  (2.2736790960109845)	Data (0.004763017885689732)	loss  (0.04467888946193881)	Prec1  (98.69670104980469) 	
Training Epoch: [16][1600/2248]	Time  (2.27313459343943)	Data (0.004626644022534744)	loss  (0.04442513419628181)	Prec1  (98.70394134521484) 	
Training Epoch: [16][1700/2248]	Time  (2.2726000864880005)	Data (0.004520184989538983)	loss  (0.04413657921800573)	Prec1  (98.71444702148438) 	
Training Epoch: [16][1800/2248]	Time  (2.2724644638709663)	Data (0.00439593144617499)	loss  (0.04422948439023781)	Prec1  (98.70774841308594) 	
Training Epoch: [16][1900/2248]	Time  (2.2723393264662146)	Data (0.004303134660354606)	loss  (0.04409305074363398)	Prec1  (98.70832824707031) 	
Training Epoch: [16][2000/2248]	Time  (2.2724504039503226)	Data (0.004221769167982537)	loss  (0.0440979732469521)	Prec1  (98.70690155029297) 	
Training Epoch: [16][2100/2248]	Time  (2.273842628770417)	Data (0.004138932688811573)	loss  (0.044019447098787995)	Prec1  (98.71080780029297) 	
Training Epoch: [16][2200/2248]	Time  (2.274717069441272)	Data (0.003995346730538576)	loss  (0.043765741907760856)	Prec1  (98.71791076660156) 	
Testing Epoch: [16][0/32]	Time  (3.7533626556396484)	Data (2.885143756866455)	loss  (2.854804039001465)	Prec1  (62.5) 	
Testing Epoch: [16][31/32]	Time  (0.714453935623169)	Data (0.09023166447877884)	loss  (3.661208061218262)	Prec1  (49.67500305175781) 	
Epoch: 16   Test Acc: 49.67500305175781

******************************
	Adjusted learning rate: 17

0.00041812033521917703
Training Epoch: [17][0/2248]	Time  (6.458902597427368)	Data (3.5997776985168457)	loss  (0.010127518326044083)	Prec1  (100.0) 	
Training Epoch: [17][100/2248]	Time  (2.315752130923885)	Data (0.0381079357449371)	loss  (0.041671629165216245)	Prec1  (98.73916625976562) 	
Training Epoch: [17][200/2248]	Time  (2.2934290568033853)	Data (0.02050349249768613)	loss  (0.043970049002129044)	Prec1  (98.71734619140625) 	
Training Epoch: [17][300/2248]	Time  (2.2885059193519264)	Data (0.014328901949911023)	loss  (0.043415441366525184)	Prec1  (98.73078918457031) 	
Training Epoch: [17][400/2248]	Time  (2.287175762385799)	Data (0.011438346563134704)	loss  (0.04267599834059539)	Prec1  (98.78623962402344) 	
Training Epoch: [17][500/2248]	Time  (2.284241529757867)	Data (0.009701837798554502)	loss  (0.04192536146177384)	Prec1  (98.78836059570312) 	
Training Epoch: [17][600/2248]	Time  (2.283307368664099)	Data (0.008428218559100108)	loss  (0.04094573993316407)	Prec1  (98.82746887207031) 	
Training Epoch: [17][700/2248]	Time  (2.2820688164693315)	Data (0.007572196179551847)	loss  (0.040756140204515845)	Prec1  (98.83982849121094) 	
Training Epoch: [17][800/2248]	Time  (2.282548553488228)	Data (0.006876360908727372)	loss  (0.040628292392032424)	Prec1  (98.83641052246094) 	
Training Epoch: [17][900/2248]	Time  (2.283187103059792)	Data (0.0063154848249056495)	loss  (0.04070278988131937)	Prec1  (98.82682800292969) 	
Training Epoch: [17][1000/2248]	Time  (2.282716172320264)	Data (0.0058998104099269874)	loss  (0.04055593699611329)	Prec1  (98.82539367675781) 	
Training Epoch: [17][1100/2248]	Time  (2.2837712084781465)	Data (0.0055983952237301585)	loss  (0.04065316774756339)	Prec1  (98.81358337402344) 	
Training Epoch: [17][1200/2248]	Time  (2.283305888171994)	Data (0.005282886220851012)	loss  (0.04077085523674579)	Prec1  (98.81023406982422) 	
Training Epoch: [17][1300/2248]	Time  (2.2827446079547364)	Data (0.0050451568600583495)	loss  (0.04075399311624473)	Prec1  (98.80560302734375) 	
Training Epoch: [17][1400/2248]	Time  (2.2823556204679436)	Data (0.004873576119999474)	loss  (0.04048508036746075)	Prec1  (98.81725311279297) 	
Training Epoch: [17][1500/2248]	Time  (2.28216809530722)	Data (0.00469106582702596)	loss  (0.04088121746790203)	Prec1  (98.80964660644531) 	
Training Epoch: [17][1600/2248]	Time  (2.281870867593969)	Data (0.004488336675097092)	loss  (0.0406885515633205)	Prec1  (98.81471252441406) 	
Training Epoch: [17][1700/2248]	Time  (2.2813306041215182)	Data (0.004386624050869233)	loss  (0.041097232775170266)	Prec1  (98.8026351928711) 	
Training Epoch: [17][1800/2248]	Time  (2.281147703205725)	Data (0.004275368558639026)	loss  (0.04136470768358693)	Prec1  (98.79580688476562) 	
Training Epoch: [17][1900/2248]	Time  (2.281305934679251)	Data (0.004168975986599107)	loss  (0.04121570345278886)	Prec1  (98.79463195800781) 	
Training Epoch: [17][2000/2248]	Time  (2.2808055034105568)	Data (0.004096734887179823)	loss  (0.04112871234928412)	Prec1  (98.79318237304688) 	
Training Epoch: [17][2100/2248]	Time  (2.28031355831976)	Data (0.004018883203563663)	loss  (0.04115575546046798)	Prec1  (98.79521942138672) 	
Training Epoch: [17][2200/2248]	Time  (2.2810210320474016)	Data (0.003924521247347286)	loss  (0.041237327191083334)	Prec1  (98.79386901855469) 	
Testing Epoch: [17][0/32]	Time  (4.019115209579468)	Data (3.0126476287841797)	loss  (3.0258116722106934)	Prec1  (57.8125) 	
Testing Epoch: [17][31/32]	Time  (0.6931471526622772)	Data (0.09422637522220612)	loss  (3.9014296951293947)	Prec1  (47.97500228881836) 	
Epoch: 17   Test Acc: 47.97500228881836

******************************
	Adjusted learning rate: 18

0.00039721431845821814
Training Epoch: [18][0/2248]	Time  (5.418602705001831)	Data (2.931124687194824)	loss  (0.0328199677169323)	Prec1  (99.21875) 	
Training Epoch: [18][100/2248]	Time  (2.3204015387166845)	Data (0.03146219489598038)	loss  (0.04356485441105791)	Prec1  (98.60767364501953) 	
Training Epoch: [18][200/2248]	Time  (2.2957723081408448)	Data (0.016739063595064836)	loss  (0.04071404781211075)	Prec1  (98.72901153564453) 	
Training Epoch: [18][300/2248]	Time  (2.288988492021529)	Data (0.0120993571424009)	loss  (0.03989846256880269)	Prec1  (98.8216323852539) 	
Training Epoch: [18][400/2248]	Time  (2.2859400359175153)	Data (0.009778695213527156)	loss  (0.03960951617884071)	Prec1  (98.84468841552734) 	
Training Epoch: [18][500/2248]	Time  (2.284100215116185)	Data (0.008163780509354826)	loss  (0.03961027967195192)	Prec1  (98.8398208618164) 	
Training Epoch: [18][600/2248]	Time  (2.284134143600845)	Data (0.007169631475616811)	loss  (0.038822836873312165)	Prec1  (98.85867309570312) 	
Training Epoch: [18][700/2248]	Time  (2.282722233705616)	Data (0.006387861240947468)	loss  (0.038663053853216764)	Prec1  (98.8509750366211) 	
Training Epoch: [18][800/2248]	Time  (2.281540133682232)	Data (0.0058503963527608005)	loss  (0.03857809506803193)	Prec1  (98.85982513427734) 	
Training Epoch: [18][900/2248]	Time  (2.2813001107693247)	Data (0.005403322067430096)	loss  (0.038787311556998154)	Prec1  (98.82942962646484) 	
Training Epoch: [18][1000/2248]	Time  (2.280618069531558)	Data (0.005088834019450398)	loss  (0.03847734934160045)	Prec1  (98.83631896972656) 	
Training Epoch: [18][1100/2248]	Time  (2.2813715302435296)	Data (0.004869499388442702)	loss  (0.03824146544318866)	Prec1  (98.8433837890625) 	
Training Epoch: [18][1200/2248]	Time  (2.281446033473019)	Data (0.00470221429740658)	loss  (0.038495388607821)	Prec1  (98.84601593017578) 	
Training Epoch: [18][1300/2248]	Time  (2.281907637242076)	Data (0.00452437316519219)	loss  (0.038770316048402864)	Prec1  (98.8332290649414) 	
Training Epoch: [18][1400/2248]	Time  (2.2813117456470193)	Data (0.004375068227535142)	loss  (0.03897910403735207)	Prec1  (98.822265625) 	
Training Epoch: [18][1500/2248]	Time  (2.2807964841815966)	Data (0.004262915140465845)	loss  (0.03871008885067594)	Prec1  (98.83411407470703) 	
Training Epoch: [18][1600/2248]	Time  (2.2802114851544752)	Data (0.004052957842157901)	loss  (0.03856683927218777)	Prec1  (98.838623046875) 	
Training Epoch: [18][1700/2248]	Time  (2.279806633124556)	Data (0.0038736606611356112)	loss  (0.03870473219862516)	Prec1  (98.83524322509766) 	
Training Epoch: [18][1800/2248]	Time  (2.2799399170459873)	Data (0.0037297841113914983)	loss  (0.03844017837235889)	Prec1  (98.84178924560547) 	
Training Epoch: [18][1900/2248]	Time  (2.2794789644619593)	Data (0.0036283633007870293)	loss  (0.038243676905668704)	Prec1  (98.8464126586914) 	
Training Epoch: [18][2000/2248]	Time  (2.279410723624737)	Data (0.0035648330457802714)	loss  (0.0380129378720902)	Prec1  (98.85369873046875) 	
Training Epoch: [18][2100/2248]	Time  (2.2789985548025764)	Data (0.0035204354040626116)	loss  (0.03801489671491005)	Prec1  (98.85397338867188) 	
Training Epoch: [18][2200/2248]	Time  (2.2787308895495846)	Data (0.0034801825671128823)	loss  (0.037878183360257674)	Prec1  (98.86060333251953) 	
Testing Epoch: [18][0/32]	Time  (4.401684284210205)	Data (2.8401761054992676)	loss  (2.776718854904175)	Prec1  (59.375) 	
Testing Epoch: [18][31/32]	Time  (0.6784353703260422)	Data (0.08883848786354065)	loss  (3.781911418914795)	Prec1  (48.900001525878906) 	
Epoch: 18   Test Acc: 48.900001525878906

******************************
	Adjusted learning rate: 19

0.0003773536025353072
